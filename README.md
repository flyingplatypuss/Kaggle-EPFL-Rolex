# Kaggle_EPFL_Rolex
Hail and welcome, we are team Rolex (Johann Gremaud and Anna Perrottet).

We have been working on building a classification model that can identify the difficulty(A1-C2) of any french text. 

### Models Scores
We have used 5 different models: 
- Logistic Regression, 
- K Nearest Neighbours
- Decision Tree
- Random Forest
- Large Language Model (LLM) with camemBERT

$\text{\color{green}{Task J: get the scores for bert model}}$

$\text{\color{yellow}{Task A: extract complete table of scores for the 5 methods}}$ 

Our most important metric is accuracy. KNN, Random Forest and Decision Tree have around 40% of accuracy. Logistic regression performs better with 47%. 
this can be explained by several factors: 
- the size of the dataset
- the complexity of the classifier
  $\text{\color{yellow}{Task A: find couple more reasons}}$
### LLM with camemBERT 

#### Confusion Matrix
$\text{\color{green}{Task J: extract the confusion Matrix}}$
#### Limitations and flaws
where do the errors come from?
$\text{\color{green}{Task J: make a quick assessment of the model?}}$
#### Further Analysis
how do the model behave?
### Link to the Video
explaining the problem, your solution, and your results, and make it exciting

$\color{#D29922}\textsf{\Large\&#x26A0;\kern{0.2cm}\normalsize Warning}$
